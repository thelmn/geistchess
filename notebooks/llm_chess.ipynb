{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KAOFbXG-AXjf"
      },
      "outputs": [],
      "source": [
        "# How good are Small LLMs at chess gameplay?\n",
        "# Can they explain their reasoning?\n",
        "# Does finetuning make them better?\n",
        "# Do reasoning (e.g. chain-of-thought) techniques improve their performance?\n",
        "# Can they be finetuned via RL selfplay?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8A6qxbDAXjh"
      },
      "source": [
        "#### Part 1: Eval off-the-shelf LLMs on chess gameplay\n",
        "\n",
        "Use huggingface LLM api and python-chess and stockfish api to evaluate LLMs on chess gameplay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PJ_jTOQhAXjj"
      },
      "outputs": [],
      "source": [
        "# install python-chess and stockfish if not already installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "awIH_24DAXjk"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  from stockfish import Stockfish\n",
        "except ImportError:\n",
        "  !pip install stockfish\n",
        "  from stockfish import Stockfish\n",
        "\n",
        "try:\n",
        "  import chess\n",
        "except ImportError:\n",
        "  !pip install python-chess\n",
        "  import chess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-a4Jz3XNAXjk"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NzEMrlI0AXjl"
      },
      "outputs": [],
      "source": [
        "STOCKFISH_REMOTE = \"https://github.com/official-stockfish/Stockfish/releases/latest/download/stockfish-ubuntu-x86-64-avx2.tar\"\n",
        "STOCKFISH_LOCAL = \"./stockfish/stockfish-ubuntu-x86-64-avx2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LwOmNjpGAXjm"
      },
      "outputs": [],
      "source": [
        "\n",
        "if not os.path.exists(STOCKFISH_LOCAL):\n",
        "  !wget -O stockfish.tar $STOCKFISH_REMOTE\n",
        "  !tar -xf stockfish.tar\n",
        "  !rm stockfish.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T6rHvIQAXjn",
        "outputId": "b1f3a4ba-7693-4bc5-903f-831171ca9c0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "os.path.exists(STOCKFISH_LOCAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t8fEbODgAXjo"
      },
      "outputs": [],
      "source": [
        "from stockfish import Stockfish\n",
        "\n",
        "stockfish_params = {\n",
        "    # \"Debug Log File\": \"\",\n",
        "    \"Contempt\": 0,\n",
        "    \"Min Split Depth\": 0,\n",
        "    \"Threads\": 1, # More threads will make the engine stronger, but should be kept at less than the number of logical processors on your computer.\n",
        "    \"Ponder\": \"false\",\n",
        "    \"Hash\": 256, # Default size is 16 MB. It's recommended that you increase this value, but keep it as some power of 2. E.g., if you're fine using 2 GB of RAM, set Hash to 2048 (11th power of 2).\n",
        "    \"MultiPV\": 1,\n",
        "    \"Skill Level\": 20,\n",
        "    \"Move Overhead\": 10,\n",
        "    \"Minimum Thinking Time\": 20,\n",
        "    \"Slow Mover\": 100,\n",
        "    \"UCI_Chess960\": \"false\",\n",
        "    \"UCI_LimitStrength\": \"false\",\n",
        "    \"UCI_Elo\": 1350\n",
        "}\n",
        "\n",
        "stockfish = Stockfish(STOCKFISH_LOCAL, parameters=stockfish_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "mcTRUadvAXjp",
        "outputId": "4ad5214d-e216-42ca-85f2-44d84f87f491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+---+---+---+---+---+\n",
            "| r | n | b | q | k | b | n | r | 8\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| p | p | p | p | p | p | p | p | 7\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   | 6\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   | 5\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   | 4\n",
            "+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   | 3\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| P | P | P | P | P | P | P | P | 2\n",
            "+---+---+---+---+---+---+---+---+\n",
            "| R | N | B | Q | K | B | N | R | 1\n",
            "+---+---+---+---+---+---+---+---+\n",
            "  a   b   c   d   e   f   g   h\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e2e4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "print(stockfish.get_board_visual())\n",
        "stockfish.get_best_move()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xYwyXUEKAXjq",
        "outputId": "7cc6fe3a-a77c-4375-cfa3-36c6a8cdcae3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "stockfish.get_fen_position()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiIlPcOAAXjq",
        "outputId": "b23dc083-7afc-46e8-d09e-941e54155ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r n b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            "P P P P P P P P\n",
            "R N B Q K B N R\n"
          ]
        }
      ],
      "source": [
        "import chess\n",
        "\n",
        "board = chess.Board()\n",
        "\n",
        "print(board)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd8BwdthAXjr",
        "outputId": "b68256a8-a9e2-43b5-8752-c3179a39ae38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r n b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . P . . .\n",
            ". . . . . . . .\n",
            "P P P P . P P P\n",
            "R N B Q K B N R\n"
          ]
        }
      ],
      "source": [
        "stockfish.set_fen_position(board.fen(), send_ucinewgame_token=True)\n",
        "best_move = stockfish.get_best_move()\n",
        "board.push_uci(best_move)\n",
        "print(board)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MwQySjpHAXjr",
        "outputId": "c657b3ac-2ff5-4c16-b06c-5b3f8561be20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e2e4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "best_move"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "37THMmNQAXjr"
      },
      "outputs": [],
      "source": [
        "board.outcome()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPMPOLWMAXjr",
        "outputId": "b13c2ddb-1af5-4536-cf66-24bd24d31b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# huggingface AutoModelForCausalLM\n",
        "try:\n",
        "  from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "except ImportError:\n",
        "  !pip install transformers\n",
        "  from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-tlaGAfAXjs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPzo-wT3AXjs",
        "outputId": "6d06064b-c210-4346-fc4b-502059bf0284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a AI chess engine. You are playing as black, and your opponent is white. It is your turn. The board is as follows:\n",
            "r n b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . P . . .\n",
            ". . . . . . . .\n",
            "P P P P . P P P\n",
            "R N B Q K B N R\n",
            "The sequence of moves so far is: [e2e4]\n",
            "Select your next moves in UCI notation. Only return your move and not additional text.\n"
          ]
        }
      ],
      "source": [
        "BASE_PROMPT = \"\"\"You are a AI chess engine. You are playing as {llm_color}, and your opponent is {opponent_color}. It is your turn. The board is as follows:\n",
        "{board}\n",
        "The sequence of moves so far is: [{history}]\n",
        "Select your next moves in UCI notation. Only return your move and not additional text.\"\"\"\n",
        "prompt = BASE_PROMPT.format(llm_color=\"black\", opponent_color=\"white\", board=board, history=f\"{best_move}\")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": prompt},\n",
        "    {\"role\": \"user\", \"content\": \"Your move?\"},\n",
        "]\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=256,\n",
        ")\n",
        "print(outputs[0][\"generated_text\"][-1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nni6AjGBScN",
        "outputId": "c4a7a91e-1986-4b93-a4d7-7193319451f3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: You are an AI playing chess. You are playing as black, and your opponent is white. It is your turn. The board is as follows:\n",
            "r n b q k b n r\n",
            "p p p p p p p p\n",
            "........\n",
            "........\n",
            ".... P...\n",
            "........\n",
            "P P P P. P P P\n",
            "R N B Q K B N R\n",
            "The sequence of moves so far is: [e2e4]\n",
            "Select your next move (in UCI notation).\n",
            "AI move: \n",
            "Player move: \n",
            "Prompt: You are an AI playing chess. You are playing as\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "go5e5GqpAXjs",
        "outputId": "da21aaeb-ad51-412b-e47d-cc3f61312d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Illegal move: e2e4! Some legal moves are: [c7c6, b7b6, a7a6, h7h5, g7g5, f7f5, e7e5, d7d5, c7c5, b7b5, a7a5]. Try again.\n",
            "Your move (in UCI notation) is:\n"
          ]
        }
      ],
      "source": [
        "# ERROR_MOVE_PROMPT=\"Illegal move: {move}! Try again.\\nYour move (in UCI notation) is:\"\n",
        "ERROR_MOVE_PROMPT=\"\"\"Illegal move: {move}! Some legal moves are: [{legal_moves}]. Try again.\n",
        "Your next move (in UCI notation) is:\"\"\"\n",
        "\n",
        "SHOW_MAX_LEGAL_MOVES = 10\n",
        "print(\n",
        "  ERROR_MOVE_PROMPT.format(move=\"e2e4\", board=board,\n",
        "  legal_moves=', '.join([m.uci() for i, m in enumerate(board.legal_moves) if i >= (SHOW_MAX_LEGAL_MOVES-1)]))\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBjGPvjJAXjt"
      },
      "outputs": [],
      "source": [
        "class LLMGame:\n",
        "  def __init__(self, model, tokenizer, stockfish, base_prompt, color='white', stockfish_time_limit=None,\n",
        "               show_legal_moves_limit=10,\n",
        "               llm_illegal_move_retries=3, llm_illegal_move_prompt=ERROR_MOVE_PROMPT):\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.stockfish = stockfish\n",
        "    self.board = chess.Board()\n",
        "    self.base_prompt = base_prompt\n",
        "    self.color = color\n",
        "    self.stockfish_time_limit = stockfish_time_limit\n",
        "    self.show_legal_moves_limit = show_legal_moves_limit\n",
        "    self.llm_illegal_move_retries = llm_illegal_move_retries\n",
        "    self.llm_illegal_move_prompt = llm_illegal_move_prompt\n",
        "    self.history = []\n",
        "    self.outcome = None\n",
        "    self.error_outcome = None\n",
        "\n",
        "  def get_prompt(self, error_move=None):\n",
        "    legal_moves = [m.uci() for i, m in enumerate(self.board.legal_moves) if i >= (self.show_legal_moves_limit-1)]\n",
        "    prompt = self.base_prompt.format(\n",
        "        llm_color=self.color,\n",
        "        opponent_color='black' if self.color == 'white' else 'white',\n",
        "        board=self.board,\n",
        "        history=', '.join(self.history),\n",
        "        legal_moves=', '.join(legal_moves)\n",
        "    )\n",
        "    if error_move:\n",
        "      prompt += ('\\n' + self.llm_illegal_move_prompt.format(\n",
        "        move=error_move,\n",
        "        board=self.board,\n",
        "        legal_moves=', '.join(legal_moves)\n",
        "      ))\n",
        "    return prompt\n",
        "\n",
        "  def make_engine_move(self):\n",
        "    if self.board.is_game_over():\n",
        "      return\n",
        "    self.stockfish.set_fen_position(self.board.fen(), send_ucinewgame_token=True)\n",
        "    if self.stockfish_time_limit:\n",
        "      move = self.stockfish.get_best_move_time(self.stockfish_time_limit)\n",
        "    else:\n",
        "      move = self.stockfish.get_best_move()\n",
        "    self.history.append(move)\n",
        "    self.board.push_uci(move)\n",
        "\n",
        "  def make_llm_move(self, retries=None):\n",
        "    if self.board.is_game_over():\n",
        "      return\n",
        "    prompt = self.get_prompt()\n",
        "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
        "    output = model.generate(input_ids, max_length=100)\n",
        "    resp = tokenizer.decode(output[0])\n",
        "    print(resp)\n",
        "    move = resp.split('\\n')[-1].strip()\n",
        "\n",
        "    if retries is None:\n",
        "      retries = self.llm_illegal_move_retries\n",
        "\n",
        "    if move not in self.board.legal_moves:\n",
        "      if retries > 0:\n",
        "        prompt = self.get_prompt(error_move=move)\n",
        "        self.llm_move(retries=retries-1)\n",
        "      raise ValueError(\"Illegal move: {move}\")\n",
        "\n",
        "    self.history.append(move)\n",
        "    self.board.push_uci(move)\n",
        "\n",
        "  def play(self):\n",
        "    self.board = chess.Board()\n",
        "    self.history = []\n",
        "    self.outcome = None\n",
        "    self.error_outcome = None\n",
        "\n",
        "    if self.color == 'black':\n",
        "      if not self.board.is_game_over():\n",
        "        try:\n",
        "          self.make_engine_move()\n",
        "          self.outcome = self.board.outcome()\n",
        "        except ValueError as e:\n",
        "          print(e)\n",
        "          self.error_outcome = ('Engine', e)\n",
        "          self.outcome = self.board.outcome()\n",
        "          return\n",
        "\n",
        "    while not self.board.is_game_over():\n",
        "      if not self.board.is_game_over():\n",
        "        try:\n",
        "          self.make_llm_move()\n",
        "          self.outcome = self.board.outcome()\n",
        "        except ValueError as e:\n",
        "          print(e)\n",
        "          self.error_outcome = ('LLM', e)\n",
        "          self.outcome = self.board.outcome()\n",
        "          return\n",
        "      if not self.board.is_game_over():\n",
        "        try:\n",
        "          self.make_engine_move()\n",
        "          self.outcome = self.board.outcome()\n",
        "        except ValueError as e:\n",
        "          print(e)\n",
        "          self.error_outcome = ('Engine', e)\n",
        "          self.outcome = self.board.outcome()\n",
        "          return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo7EVN-jAXjt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}